{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cyclegan.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8r-IrF5DmVKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install necessary tools for mounting Google Drive."
      ]
    },
    {
      "metadata": {
        "id": "avBbKdzTsCtR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADo0VN67nKDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive."
      ]
    },
    {
      "metadata": {
        "id": "vIsFkalDsJxi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!fusermount -u drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vJwweVSnDH8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaR92bAGmkaO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run this cell in order to check whether google drive is mounted."
      ]
    },
    {
      "metadata": {
        "id": "OYUcP6QlmADc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls && ls drive "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ci5bLSfDpD4p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports."
      ]
    },
    {
      "metadata": {
        "id": "5rJzb4L6s_qF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from absl import flags\n",
        "import numpy as np\n",
        "from six.moves import xrange \n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.contrib.gan.python.eval.python import eval_utils\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.summary import summary\n",
        "\n",
        "layers = tf.contrib.layers\n",
        "tfgan = tf.contrib.gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y-J-0LqDpS5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check if GPU is avaliable."
      ]
    },
    {
      "metadata": {
        "id": "bBsnFsnvHeDq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P6rMuf0Wpg6T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CycleGAN generator with ResNet blocks."
      ]
    },
    {
      "metadata": {
        "id": "7dJdpbl7tFbC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def cyclegan_arg_scope(instance_norm_center=True,\n",
        "                       instance_norm_scale=True,\n",
        "                       instance_norm_epsilon=0.001,\n",
        "                       weights_init_stddev=0.02,\n",
        "                       weight_decay=0.0):\n",
        "  instance_norm_params = {\n",
        "      'center': instance_norm_center,\n",
        "      'scale': instance_norm_scale,\n",
        "  }\n",
        "\n",
        "  weights_regularizer = None\n",
        "  if weight_decay and weight_decay > 0.0:\n",
        "    weights_regularizer = layers.l2_regularizer(weight_decay)\n",
        "\n",
        "  with tf.contrib.framework.arg_scope(\n",
        "      [layers.conv2d],\n",
        "      normalizer_fn=layers.instance_norm,\n",
        "      normalizer_params=instance_norm_params,\n",
        "      weights_initializer=tf.random_normal_initializer(0, weights_init_stddev),\n",
        "      weights_regularizer=weights_regularizer) as sc:\n",
        "    return sc\n",
        "\n",
        "\n",
        "def cyclegan_upsample(net, num_outputs, stride, method='conv2d_transpose'):\n",
        "  with tf.variable_scope('upconv'):\n",
        "    net_shape = tf.shape(net)\n",
        "    height = net_shape[1]\n",
        "    width = net_shape[2]\n",
        "\n",
        "    spatial_pad_1 = np.array([[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "\n",
        "    if method == 'nn_upsample_conv':\n",
        "      net = tf.image.resize_nearest_neighbor(\n",
        "          net, [stride[0] * height, stride[1] * width])\n",
        "      net = tf.pad(net, spatial_pad_1, 'REFLECT')\n",
        "      net = layers.conv2d(net, num_outputs, kernel_size=[3, 3], padding='valid')\n",
        "    elif method == 'bilinear_upsample_conv':\n",
        "      net = tf.image.resize_bilinear(\n",
        "          net, [stride[0] * height, stride[1] * width])\n",
        "      net = tf.pad(net, spatial_pad_1, 'REFLECT')\n",
        "      net = layers.conv2d(net, num_outputs, kernel_size=[3, 3], padding='valid')\n",
        "    elif method == 'conv2d_transpose':\n",
        "      net = layers.conv2d_transpose(\n",
        "          net, num_outputs, kernel_size=[3, 3], stride=stride, padding='valid')\n",
        "      net = net[:, 1:, 1:, :]\n",
        "    else:\n",
        "      raise ValueError('Unknown method: [%s]', method)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "def _dynamic_or_static_shape(tensor):\n",
        "  shape = tf.shape(tensor)\n",
        "  static_shape = tf.contrib.util.constant_value(shape)\n",
        "  return static_shape if static_shape is not None else shape\n",
        "\n",
        "\n",
        "def cyclegan_generator_resnet(images,\n",
        "                              arg_scope_fn=cyclegan_arg_scope,\n",
        "                              num_resnet_blocks=6,\n",
        "                              num_filters=64,\n",
        "                              upsample_fn=cyclegan_upsample,\n",
        "                              kernel_size=3,\n",
        "                              num_outputs=3,\n",
        "                              tanh_linear_slope=0.0,\n",
        "                              is_training=False):\n",
        "  del is_training\n",
        "\n",
        "  end_points = {}\n",
        "\n",
        "  input_size = images.shape.as_list()\n",
        "  height, width = input_size[1], input_size[2]\n",
        "  if height and height % 4 != 0:\n",
        "    raise ValueError('The input height must be a multiple of 4.')\n",
        "  if width and width % 4 != 0:\n",
        "    raise ValueError('The input width must be a multiple of 4.')\n",
        "\n",
        "  if not isinstance(kernel_size, (list, tuple)):\n",
        "    kernel_size = [kernel_size, kernel_size]\n",
        "\n",
        "  kernel_height = kernel_size[0]\n",
        "  kernel_width = kernel_size[1]\n",
        "  pad_top = (kernel_height - 1) // 2\n",
        "  pad_bottom = kernel_height // 2\n",
        "  pad_left = (kernel_width - 1) // 2\n",
        "  pad_right = kernel_width // 2\n",
        "  paddings = np.array(\n",
        "      [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]],\n",
        "      dtype=np.int32)\n",
        "  spatial_pad_3 = np.array([[0, 0], [3, 3], [3, 3], [0, 0]])\n",
        "\n",
        "  with tf.contrib.framework.arg_scope(arg_scope_fn()):\n",
        "    with tf.variable_scope('input'):\n",
        "      # 7x7 input stage\n",
        "      net = tf.pad(images, spatial_pad_3, 'REFLECT')\n",
        "      net = layers.conv2d(\n",
        "          net, num_filters, kernel_size=[7, 7], padding='VALID')\n",
        "      end_points['encoder_0'] = net\n",
        "\n",
        "    with tf.variable_scope('encoder'):\n",
        "      with tf.contrib.framework.arg_scope(\n",
        "          [layers.conv2d],\n",
        "          kernel_size=kernel_size,\n",
        "          stride=2,\n",
        "          activation_fn=tf.nn.relu,\n",
        "          padding='VALID'):\n",
        "\n",
        "        net = tf.pad(net, paddings, 'REFLECT')\n",
        "        net = layers.conv2d(net, num_filters * 2)\n",
        "        end_points['encoder_1'] = net\n",
        "        net = tf.pad(net, paddings, 'REFLECT')\n",
        "        net = layers.conv2d(net, num_filters * 4)\n",
        "        end_points['encoder_2'] = net\n",
        "\n",
        "    with tf.variable_scope('residual_blocks'):\n",
        "      with tf.contrib.framework.arg_scope(\n",
        "          [layers.conv2d],\n",
        "          kernel_size=kernel_size,\n",
        "          stride=1,\n",
        "          activation_fn=tf.nn.relu,\n",
        "          padding='VALID'):\n",
        "        for block_id in xrange(num_resnet_blocks):\n",
        "          with tf.variable_scope('block_{}'.format(block_id)):\n",
        "            res_net = tf.pad(net, paddings, 'REFLECT')\n",
        "            res_net = layers.conv2d(res_net, num_filters * 4)\n",
        "            res_net = tf.pad(res_net, paddings, 'REFLECT')\n",
        "            res_net = layers.conv2d(res_net, num_filters * 4,\n",
        "                                    activation_fn=None)\n",
        "            net += res_net\n",
        "\n",
        "            end_points['resnet_block_%d' % block_id] = net\n",
        "\n",
        "    with tf.variable_scope('decoder'):\n",
        "      with tf.contrib.framework.arg_scope(\n",
        "          [layers.conv2d],\n",
        "          kernel_size=kernel_size,\n",
        "          stride=1,\n",
        "          activation_fn=tf.nn.relu):\n",
        "\n",
        "        with tf.variable_scope('decoder1'):\n",
        "          net = upsample_fn(net, num_outputs=num_filters * 2, stride=[2, 2])\n",
        "        end_points['decoder1'] = net\n",
        "\n",
        "        with tf.variable_scope('decoder2'):\n",
        "          net = upsample_fn(net, num_outputs=num_filters, stride=[2, 2])\n",
        "        end_points['decoder2'] = net\n",
        "\n",
        "    with tf.variable_scope('output'):\n",
        "      net = tf.pad(net, spatial_pad_3, 'REFLECT')\n",
        "      logits = layers.conv2d(\n",
        "          net,\n",
        "          num_outputs, [7, 7],\n",
        "          activation_fn=None,\n",
        "          normalizer_fn=None,\n",
        "          padding='valid')\n",
        "      logits = tf.reshape(logits, _dynamic_or_static_shape(images))\n",
        "\n",
        "      end_points['logits'] = logits\n",
        "      end_points['predictions'] = tf.tanh(logits) + logits * tanh_linear_slope\n",
        "\n",
        "  return end_points['predictions'], end_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJXRLlONp4I-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pix2pix discriminator."
      ]
    },
    {
      "metadata": {
        "id": "4TlFES8OtOP1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def pix2pix_arg_scope():\n",
        "  instance_norm_params = {\n",
        "      'center': True,\n",
        "      'scale': True,\n",
        "      'epsilon': 0.00001,\n",
        "  }\n",
        "\n",
        "  with tf.contrib.framework.arg_scope(\n",
        "      [layers.conv2d, layers.conv2d_transpose],\n",
        "      normalizer_fn=layers.instance_norm,\n",
        "      normalizer_params=instance_norm_params,\n",
        "      weights_initializer=tf.random_normal_initializer(0, 0.02)) as sc:\n",
        "    return sc\n",
        "\n",
        "\n",
        "def pix2pix_discriminator(net, num_filters, padding=2, is_training=False):\n",
        "  del is_training\n",
        "  end_points = {}\n",
        "\n",
        "  num_layers = len(num_filters)\n",
        "\n",
        "  def padded(net, scope):\n",
        "    if padding:\n",
        "      with tf.variable_scope(scope):\n",
        "        spatial_pad = tf.constant(\n",
        "            [[0, 0], [padding, padding], [padding, padding], [0, 0]],\n",
        "            dtype=tf.int32)\n",
        "        return tf.pad(net, spatial_pad, 'REFLECT')\n",
        "    else:\n",
        "      return net\n",
        "\n",
        "  with tf.contrib.framework.arg_scope(\n",
        "      [layers.conv2d],\n",
        "      kernel_size=[4, 4],\n",
        "      stride=2,\n",
        "      padding='valid',\n",
        "      activation_fn=tf.nn.leaky_relu):\n",
        "\n",
        "    net = layers.conv2d(\n",
        "        padded(net, 'conv0'), num_filters[0], normalizer_fn=None, scope='conv0')\n",
        "\n",
        "    end_points['conv0'] = net\n",
        "\n",
        "    for i in range(1, num_layers - 1):\n",
        "      net = layers.conv2d(\n",
        "          padded(net, 'conv%d' % i), num_filters[i], scope='conv%d' % i)\n",
        "      end_points['conv%d' % i] = net\n",
        "\n",
        "    net = layers.conv2d(\n",
        "        padded(net, 'conv%d' % (num_layers - 1)),\n",
        "        num_filters[-1],\n",
        "        stride=1,\n",
        "        scope='conv%d' % (num_layers - 1))\n",
        "    end_points['conv%d' % (num_layers - 1)] = net\n",
        "\n",
        "    logits = layers.conv2d(\n",
        "        padded(net, 'conv%d' % num_layers),\n",
        "        1,\n",
        "        stride=1,\n",
        "        activation_fn=None,\n",
        "        normalizer_fn=None,\n",
        "        scope='conv%d' % num_layers)\n",
        "    end_points['logits'] = logits\n",
        "    end_points['predictions'] = tf.sigmoid(logits)\n",
        "  return logits, end_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kVIzQv5qKK-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Networks (wrappers)."
      ]
    },
    {
      "metadata": {
        "id": "Q0kJcIUNtUz0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def generator(input_images, num_resnet_blocks):\n",
        "  input_images.shape.assert_has_rank(4)\n",
        "  input_size = input_images.shape.as_list()\n",
        "  channels = input_size[-1]\n",
        "  if channels is None:\n",
        "    raise ValueError(\n",
        "        'Last dimension shape must be known but is None: %s' % input_size)\n",
        "  with tf.contrib.framework.arg_scope(cyclegan_arg_scope()):\n",
        "    output_images, _ = cyclegan_generator_resnet(\n",
        "        input_images, num_outputs=channels,\n",
        "        num_resnet_blocks=num_resnet_blocks)\n",
        "  return output_images\n",
        "\n",
        "\n",
        "def discriminator(image_batch, unused_conditioning=None):\n",
        "  with tf.contrib.framework.arg_scope(pix2pix_arg_scope()):\n",
        "    logits_4d, _ = pix2pix_discriminator(\n",
        "        image_batch, num_filters=[64, 128, 256, 512])\n",
        "    logits_4d.shape.assert_has_rank(4)\n",
        "  logits_2d = tf.contrib.layers.flatten(logits_4d)\n",
        "  return logits_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7qBGPodqZlS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data Provider."
      ]
    },
    {
      "metadata": {
        "id": "jh6jRvQltZVH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "  return (tf.to_float(image) - 127.5) / 127.5\n",
        "\n",
        "\n",
        "def undo_normalize_image(normalized_image):\n",
        "  normalized_image = np.squeeze(normalized_image, axis=0)\n",
        "  return np.uint8(normalized_image * 127.5 + 127.5)\n",
        "\n",
        "\n",
        "def _sample_patch(image, patch_size, training=True):\n",
        "  image_shape = tf.shape(image)\n",
        "  height, width = image_shape[0], image_shape[1]\n",
        "  target_size = tf.minimum(height, width)\n",
        "  image = tf.image.resize_image_with_crop_or_pad(image, target_size,\n",
        "                                                 target_size)\n",
        "  image = tf.expand_dims(image, axis=0)\n",
        "\n",
        "  if training:\n",
        "    scale_size = int(patch_size * 1.172)\n",
        "    image = tf.image.resize_images(image, [scale_size, scale_size])\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "    seed = 9\n",
        "    image = tf.image.random_flip_left_right(image, seed=seed)\n",
        "    image = tf.random_crop(\n",
        "        image, [patch_size, patch_size, image_shape[2]], seed=seed)\n",
        "  else:\n",
        "    image = tf.image.resize_images(image, [patch_size, patch_size])\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  image = tf.tile(image, [1, 1, tf.maximum(1, 4 - tf.shape(image)[2])])\n",
        "  image = tf.slice(image, [0, 0, 0], [patch_size, patch_size, 3])\n",
        "  return image\n",
        "\n",
        "\n",
        "def full_image_to_patch(image, patch_size, training=True):\n",
        "  image = normalize_image(image)\n",
        "  image_patch = _sample_patch(image, patch_size, training=training)\n",
        "  image_patch.shape.assert_is_compatible_with([patch_size, patch_size, 3])\n",
        "  return image_patch\n",
        "\n",
        "\n",
        "def parse_dataset(filename, patch_size):\n",
        "  image_string = tf.read_file(filename)\n",
        "  image_bytes = tf.image.decode_image(image_string)\n",
        "  image_patch = full_image_to_patch(image_bytes, patch_size)\n",
        "  return image_patch\n",
        "\n",
        "\n",
        "def provide_custom_datasets(image_file_patterns,\n",
        "                            batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_threads=1,\n",
        "                            patch_size=128):\n",
        "\n",
        "  outputs = []\n",
        "\n",
        "  for p in image_file_patterns:\n",
        "    filenames = tf.gfile.Glob(p)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
        "    dataset = dataset.map(lambda f: parse_dataset(f, patch_size))\n",
        "    dataset = dataset.shuffle(1500, seed=5)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.repeat()\n",
        "    im = dataset.make_one_shot_iterator().get_next()\n",
        "    outputs.append(im)\n",
        "  return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1lCukV79qypU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training."
      ]
    },
    {
      "metadata": {
        "id": "wnCODt-4q0PH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "image_set_x_file_pattern = 'drive/app/horse2zebra/trainA/*.jpg'\n",
        "image_set_y_file_pattern = 'drive/app/horse2zebra/trainB/*.jpg'\n",
        "batch_size = 1\n",
        "patch_size = 256\n",
        "master = ''\n",
        "train_log_dir = 'drive/app/checkpoints'\n",
        "generator_lr = 0.0001\n",
        "discriminator_lr = 0.0001\n",
        "max_number_of_steps = 500000\n",
        "ps_tasks = 0\n",
        "task = 0\n",
        "cycle_consistency_loss_weight = 10.0\n",
        "num_resnet_blocks = 9\n",
        "\n",
        "\n",
        "def _assert_is_image(data):\n",
        "  data.shape.assert_has_rank(4)\n",
        "  data.shape[1:].assert_is_fully_defined()\n",
        "\n",
        "\n",
        "def add_cyclegan_image_summaries(cyclegan_model, batch_size):\n",
        "  if not isinstance(cyclegan_model, tf.contrib.gan.CycleGANModel):\n",
        "    raise ValueError('`cyclegan_model` was not a CycleGANModel. Instead, was '\n",
        "                     '%s' % type(cyclegan_model))\n",
        "\n",
        "  _assert_is_image(cyclegan_model.model_x2y.generator_inputs)\n",
        "  _assert_is_image(cyclegan_model.model_x2y.generated_data)\n",
        "  _assert_is_image(cyclegan_model.reconstructed_x)\n",
        "  _assert_is_image(cyclegan_model.model_y2x.generator_inputs)\n",
        "  _assert_is_image(cyclegan_model.model_y2x.generated_data)\n",
        "  _assert_is_image(cyclegan_model.reconstructed_y)\n",
        "\n",
        "  def _add_comparison_summary(gan_model, reconstructions):\n",
        "    image_list = (\n",
        "        array_ops.unstack(gan_model.generator_inputs[:1], num=batch_size) +\n",
        "        array_ops.unstack(gan_model.generated_data[:1], num=batch_size) +\n",
        "        array_ops.unstack(reconstructions[:1], num=batch_size))\n",
        "    summary.image(\n",
        "        'image_comparison', eval_utils.image_reshaper(\n",
        "            image_list, num_cols=len(image_list)), max_outputs=1)\n",
        "\n",
        "  with ops.name_scope('x2y_image_comparison_summaries'):\n",
        "    _add_comparison_summary(\n",
        "        cyclegan_model.model_x2y, cyclegan_model.reconstructed_x)\n",
        "  with ops.name_scope('y2x_image_comparison_summaries'):\n",
        "    _add_comparison_summary(\n",
        "        cyclegan_model.model_y2x, cyclegan_model.reconstructed_y)\n",
        "\n",
        "\n",
        "def _define_model(images_x, images_y):\n",
        "  cyclegan_model = tfgan.cyclegan_model(\n",
        "      generator_fn=lambda x: generator(x, num_resnet_blocks),\n",
        "      discriminator_fn=discriminator,\n",
        "      data_x=images_x,\n",
        "      data_y=images_y)\n",
        "\n",
        "  add_cyclegan_image_summaries(cyclegan_model, batch_size)\n",
        "\n",
        "  return cyclegan_model\n",
        "\n",
        "\n",
        "def _get_lr(base_lr):\n",
        "  global_step = tf.train.get_or_create_global_step()\n",
        "  lr_constant_steps = max_number_of_steps // 2\n",
        "\n",
        "  def _lr_decay():\n",
        "    return tf.train.polynomial_decay(\n",
        "        learning_rate=base_lr,\n",
        "        global_step=(global_step - lr_constant_steps),\n",
        "        decay_steps=(max_number_of_steps - lr_constant_steps),\n",
        "        end_learning_rate=0.0)\n",
        "\n",
        "  return tf.cond(global_step < lr_constant_steps, lambda: base_lr, _lr_decay)\n",
        "\n",
        "\n",
        "def _get_optimizer(gen_lr, dis_lr):\n",
        "  gen_opt = tf.train.AdamOptimizer(\n",
        "      gen_lr, beta1=0.5, beta2=0.9, use_locking=True)\n",
        "  dis_opt = tf.train.AdamOptimizer(\n",
        "      dis_lr, beta1=0.5, beta2=0.9, use_locking=True)\n",
        "  return gen_opt, dis_opt\n",
        "\n",
        "\n",
        "def _define_train_ops(cyclegan_model, cyclegan_loss):\n",
        "  gen_lr = _get_lr(generator_lr)\n",
        "  dis_lr = _get_lr(discriminator_lr)\n",
        "  gen_opt, dis_opt = _get_optimizer(gen_lr, dis_lr)\n",
        "  train_ops = tfgan.gan_train_ops(\n",
        "      cyclegan_model,\n",
        "      cyclegan_loss,\n",
        "      generator_optimizer=gen_opt,\n",
        "      discriminator_optimizer=dis_opt,\n",
        "      summarize_gradients=True,\n",
        "      colocate_gradients_with_ops=True,\n",
        "      aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n",
        "\n",
        "  tf.summary.scalar('generator_lr', gen_lr)\n",
        "  tf.summary.scalar('discriminator_lr', dis_lr)\n",
        "  return train_ops\n",
        "\n",
        "\n",
        "def main():\n",
        "  tf.set_random_seed(10)\n",
        "\n",
        "  if not tf.gfile.Exists(train_log_dir):\n",
        "    tf.gfile.MakeDirs(train_log_dir)\n",
        "\n",
        "  with tf.device(tf.train.replica_device_setter(ps_tasks)):\n",
        "    with tf.name_scope('inputs'):\n",
        "      images_x, images_y = provide_custom_datasets(\n",
        "          [image_set_x_file_pattern, image_set_y_file_pattern],\n",
        "          batch_size=batch_size,\n",
        "          patch_size=patch_size)\n",
        "\n",
        "    cyclegan_model = _define_model(images_x, images_y)\n",
        "\n",
        "    cyclegan_loss = tfgan.cyclegan_loss(\n",
        "        cyclegan_model,\n",
        "        cycle_consistency_loss_weight=cycle_consistency_loss_weight,\n",
        "        tensor_pool_fn=tfgan.features.tensor_pool)\n",
        "\n",
        "    train_ops = _define_train_ops(cyclegan_model, cyclegan_loss)\n",
        "\n",
        "    train_steps = tfgan.GANTrainSteps(1, 1)\n",
        "    status_message = tf.string_join(\n",
        "        [\n",
        "            'Starting train step: ',\n",
        "            tf.as_string(tf.train.get_or_create_global_step())\n",
        "        ],\n",
        "        name='status_message')\n",
        "    if not max_number_of_steps:\n",
        "      return\n",
        "\n",
        "    tfgan.gan_train(\n",
        "        train_ops,\n",
        "        train_log_dir,\n",
        "        get_hooks_fn=tfgan.get_sequential_train_hooks(train_steps),\n",
        "        hooks=[\n",
        "            tf.train.StopAtStepHook(num_steps=max_number_of_steps),\n",
        "            tf.train.LoggingTensorHook([status_message], every_n_iter=10)\n",
        "        ],\n",
        "        master=master,\n",
        "        is_chief=task == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3T-VPhserLOo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start training."
      ]
    },
    {
      "metadata": {
        "id": "tXKSuGo-UjML",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}